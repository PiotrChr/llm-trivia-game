version: '3'

services:
  backend:
    build:
      context: .
      dockerfile: ./docker/backend.Dockerfile
    image: piotrchrusciel/llmtrivia-backend:latest
    environment:
      - BACKEND_PORT=5000
      - FRONTEND_HOST=nginx-frontend
      - MODEL=gpt-3.5-turbo
      - TEMPERATURE=0.9
      - OPENAI_KEY=secret
      - SECRET_KEY=secret
    expose:
      - "5000"
    networks:
      - llm_network

  nginx-backend:
    image: nginx:latest
    ports:
      - "8002:8002"
    volumes:
      - ./resources/nginx/backend.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - backend
    networks:
      - llm_network

  frontend:
    build:
      context: .
      dockerfile: ./docker/frontend.Dockerfile
      args:
        - API_HOST=nginx-backend
        - API_PORT=8080
    image: piotrchrusciel/llmtrivia-frontend:latest
    depends_on:
      - backend
    networks:
      - llm_network
    ports:
      - "8001:8001"
    expose:
      - "8001"
    
networks:
  llm_network:
    driver: bridge